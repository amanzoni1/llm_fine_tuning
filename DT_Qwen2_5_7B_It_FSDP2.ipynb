{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Distributed Training - Qwen2.5-7B-Instruct with FSDP2\n\nThis Kaggle notebook demonstrates fine-tuning the Qwen2.5-7B-Instruct model using Fully Sharded Data Parallelism version 2 (FSDP2) with QLoRA (4-bit quantization via BitsAndBytes) for parameter-efficient training. The setup runs on Kaggle's free dual T4 GPUs, leveraging mixed precision, CPU offloading, activation checkpointing, and LoRA adapters to minimize VRAM usage during distributed training.\n\nThe training logic is in a Python script (required for Accelerate’s multi-process launch) with inline comments for clarity. Post-training, we plot the training loss to visualize progress.\n\nThis aligns with the repo’s focus on efficient, GPU-friendly fine-tuning.","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Setup","metadata":{}},{"cell_type":"code","source":"!pip install --quiet trl accelerate==1.10.1 peft bitsandbytes git+https://github.com/huggingface/transformers.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T14:44:55.766468Z","iopub.execute_input":"2025-10-21T14:44:55.766719Z","iopub.status.idle":"2025-10-21T14:47:04.902940Z","shell.execute_reply.started":"2025-10-21T14:44:55.766700Z","shell.execute_reply":"2025-10-21T14:47:04.902202Z"}},"outputs":[{"name":"stdout","text":"  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.9/374.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.1/423.1 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.0/502.0 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\nbigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\nsentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 5.0.0.dev0 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\npandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Accelerate FSDP2 Configuration\nThe YAML config enables FSDP2 with:\n\n\n\n\n\n- Sharding (version 2) and auto-wrapping for transformer layers.\n\n- Optimizations: Reshard after forward, activation checkpointing, CPU offload, FP16 mixed precision.\n\n\n\n- Full state dict for saving.\n\nThese reduce per-GPU memory usage for the 7B model.","metadata":{}},{"cell_type":"code","source":"%%writefile /kaggle/working/fsdp2_config.yaml\n\ncompute_environment: LOCAL_MACHINE\ndistributed_type: FSDP\ndowncast_bf16: no\nfsdp_config:\n  fsdp_version: 2\n  reshard_after_forward: true\n  transformer_cls_names_to_wrap: Qwen2DecoderLayer\n  auto_wrap_policy: TRANSFORMER_BASED_WRAP  \n  state_dict_type: FULL_STATE_DICT\n  activation_checkpointing: true\n  cpu_offload: true\n  limit_all_gathers: true\n  mixed_precision_policy:\n    param_dtype: float16\n    reduce_dtype: float32\n    output_dtype: float16\n    cast_forward_inputs: true\nmachine_rank: 0\nmain_training_function: main\nmixed_precision: fp16\nnum_machines: 1\nnum_processes: 2\nrdzv_backend: static\nsame_network: true\ntpu_env: []\ntpu_use_cluster: false\ntpu_use_sudo: false\nuse_cpu: false","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T14:47:04.904783Z","iopub.execute_input":"2025-10-21T14:47:04.905288Z","iopub.status.idle":"2025-10-21T14:47:04.910630Z","shell.execute_reply.started":"2025-10-21T14:47:04.905267Z","shell.execute_reply":"2025-10-21T14:47:04.909986Z"}},"outputs":[{"name":"stdout","text":"Writing /kaggle/working/fsdp2_config.yaml\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Training Script","metadata":{}},{"cell_type":"code","source":"%%writefile fsdp2_train.py\n\nimport os, gc, torch, json\nfrom torch.distributed import destroy_process_group\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainerCallback\nfrom peft import get_peft_model, LoraConfig, TaskType\nfrom peft.utils.other import fsdp_auto_wrap_policy\nfrom trl import SFTTrainer, SFTConfig\nfrom datasets import load_dataset\nfrom huggingface_hub import login\n\n# Define training hyperparameters as a dict for easy modification\nTRAIN_CONFIG = {\n    \"seed\": 123,  # For reproducibility\n    \"max_steps\": 100,  # Limited number of steps for demo\n    \"warmup_steps\": 5,  # Quick warmup to stabilize LR\n    \"batch_size\": 1,   # Per-device batch size\n    \"grad_accum_steps\": 8,  # Accumulate gradients for effective larger batch\n    \"max_seq_length\": 1024,  # Balance context vs. memor\n    \"learning_rate\": 5e-5,  # Conservative LR for stable training\n    \"logging_steps\": 5,  # Frequent logging for monitoring\n    \"output_dir\": \"/kaggle/working/output\",\n}\n\n# Environment variables for optimization\nos.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\"  # Faster HF downloads\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"  # Use both GPUs\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True,roundup_power2_divisions:[32:256,64:128,256:64,>:32]\"  # Optimize CUDA memory allocation\n\n# Custom callback to log GPU memory usage and save training logs\nclass GPUUsageCallback(TrainerCallback):\n    def on_log(self, args, state, control, logs=None, **kwargs):\n        if state.is_local_process_zero:  # Only save on rank 0 to avoid duplicates\n            mem_alloc = torch.cuda.memory_allocated() / 1e9\n            mem_reserved = torch.cuda.memory_reserved() / 1e9\n            mem_peak = torch.cuda.max_memory_allocated() / 1e9\n            print(f\"[Mem Alloc = {mem_alloc:.2f}GB, Mem Reserved = {mem_reserved:.2f}GB, Mem Peak = {mem_peak:.2f}GB]\")\n            \n            # Save step and loss to JSON\n            logs_to_save = {\"step\": state.global_step, \"loss\": logs.get(\"loss\", None), \"mem_alloc\": mem_alloc, \"mem_reserved\": mem_reserved}\n            with open(os.path.join(args.output_dir, \"train_logs.json\"), \"a\") as f:\n                f.write(json.dumps(logs_to_save) + \"\\n\")\n                \n        return control\n\n# Function to load dataset, model, and tokenizer\ndef load_train_objs():\n    local_rank = int(os.environ.get(\"LOCAL_RANK\", -1))\n    if local_rank != -1:\n        torch.cuda.set_device(local_rank)  # Set device per process\n\n    model_name = \"Qwen/Qwen2.5-7B-Instruct\"\n\n    # Load tokenizer and set pad token\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    tokenizer.pad_token = tokenizer.eos_token\n\n    # 4-bit quantization config for QLoRA\n    bnb_cfg = BitsAndBytesConfig(\n        load_in_4bit              = True,\n        bnb_4bit_use_double_quant = True,  # Nested quantization for extra savings\n        bnb_4bit_quant_type       = \"nf4\",  # Normalized float4 for better precision\n        bnb_4bit_compute_dtype    = torch.float16,  # FP16 for computations\n        bnb_4bit_quant_storage    = torch.float16,  # Store quantized weights in FP16\n    )\n\n    # Load model with quantization and device mapping\n    model = AutoModelForCausalLM.from_pretrained(\n        model_name,\n        dtype               = torch.float16,  # Overall dtype\n        device_map          = {\"\": local_rank} if local_rank != -1 else \"auto\",  # Map to process device\n        attn_implementation = \"sdpa\",  # Scaled dot-product attention for efficiency\n        low_cpu_mem_usage   = True,  # Reduce CPU memory during loading\n        quantization_config = bnb_cfg,\n    )\n\n    # Load dataset (10% for demo)\n    url = \"https://huggingface.co/datasets/laion/OIG/resolve/main/unified_chip2.jsonl\"\n    dataset = load_dataset(\"json\", data_files={\"train\": url}, split=\"train[:10%]\")\n\n    return dataset, model, tokenizer\n\n# Function to apply LoRA adapters\ndef apply_lora(model):\n    # LoRA config: Target key modules, low dropout, causal LM task\n    lora_cfg = LoraConfig(\n        r              = 16,  # Rank of adapters\n        lora_alpha     = 32,  # Scaling factor\n        target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n        lora_dropout   = 0.0,\n        bias           = \"none\",\n        task_type      = TaskType.CAUSAL_LM,\n    )\n\n    # Get LoRA and setup model\n    model = get_peft_model(model, lora_cfg)\n\n    # Freeze base model, only train LoRA params\n    with torch.no_grad():\n        for name, param in model.named_parameters():\n            if \".lora_A.\" in name or \".lora_B.\" in name:\n                param.requires_grad_(True)\n            else:\n                param.requires_grad_(False)\n\n    model.enable_input_require_grads()  # For gradient checkpointing if enabled\n    model.config.use_cache = False  # Disable cache during training\n\n    return model\n\n# Main training function\ndef main():\n    # Load objects\n    dataset, model, tokenizer = load_train_objs()\n    model = apply_lora(model)\n\n    # Clear cache before training\n    torch.cuda.empty_cache()\n    gc.collect()\n    \n    # SFTTrainer args with FSDP integration\n    training_args = SFTConfig(\n        seed                        = TRAIN_CONFIG[\"seed\"],\n        max_steps                   = TRAIN_CONFIG[\"max_steps\"],\n        warmup_steps                = TRAIN_CONFIG[\"warmup_steps\"],\n        per_device_train_batch_size = TRAIN_CONFIG[\"batch_size\"],\n        gradient_accumulation_steps = TRAIN_CONFIG[\"grad_accum_steps\"],\n        max_length                  = TRAIN_CONFIG[\"max_seq_length\"],\n        learning_rate               = TRAIN_CONFIG[\"learning_rate\"],\n        logging_steps               = TRAIN_CONFIG[\"logging_steps\"],\n        output_dir                  = TRAIN_CONFIG[\"output_dir\"],\n        fp16                        = model.get_input_embeddings().weight.dtype == torch.float16,\n        bf16                        = model.get_input_embeddings().weight.dtype == torch.bfloat16,\n        fsdp                        = \"full_shard\",  # Full sharding for FSDP\n        gradient_checkpointing      = False,  # Disabled here; enabled in FSDP2 config\n        report_to                   = \"none\",  # No external logging\n    )\n\n    # Initialize trainer\n    trainer = SFTTrainer(\n        model            = model,\n        args             = training_args,\n        train_dataset    = dataset,\n        processing_class = tokenizer,\n        callbacks        = [GPUUsageCallback()],  # Memory logging\n    )\n\n    # Print FSDP setup info\n    rank = trainer.accelerator.process_index\n    print(f\"[Rank {rank}] Plugin FSDP version: {trainer.accelerator.state.fsdp_plugin.fsdp_version}\")\n    print(f\"[Rank {rank}] is_fsdp2: {trainer.accelerator.is_fsdp2}\")\n    print(f\"[Rank {rank}] Distributed type: {trainer.accelerator.state.distributed_type}\")\n    print(f\"[Rank {rank}] Device: {trainer.accelerator.device}\")\n\n    # Pre-training memory check\n    rank = int(os.environ.get(\"LOCAL_RANK\", 0))\n    mem_alloc = torch.cuda.memory_allocated() / 1e9\n    mem_reserved = torch.cuda.memory_reserved() / 1e9\n    print(f\"[Rank {rank}] Pre-training Mem Alloc = {mem_alloc:.2f}GB, Mem Reserved = {mem_reserved:.2f}GB\")\n\n    # Print trainable params\n    trainer.model.print_trainable_parameters()\n\n    # Start training\n    trainer.train()\n\n    # Save model with full state dict\n    if trainer.is_fsdp_enabled:\n        trainer.accelerator.state.fsdp_plugin.set_state_dict_type(\"FULL_STATE_DICT\")\n    trainer.save_model()\n\n    # Clean up distributed processes\n    destroy_process_group()\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T14:47:04.911440Z","iopub.execute_input":"2025-10-21T14:47:04.911675Z","iopub.status.idle":"2025-10-21T14:47:04.951143Z","shell.execute_reply.started":"2025-10-21T14:47:04.911653Z","shell.execute_reply":"2025-10-21T14:47:04.950647Z"}},"outputs":[{"name":"stdout","text":"Writing fsdp2_train.py\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Launch Training\n\nLaunch with Accelerate using 2 GPUs. Monitor memory usage and training progress","metadata":{}},{"cell_type":"code","source":"!accelerate launch --config_file fsdp2_config.yaml --num_processes 2 fsdp2_train.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T14:47:04.951927Z","iopub.execute_input":"2025-10-21T14:47:04.952284Z","iopub.status.idle":"2025-10-21T15:14:18.099651Z","shell.execute_reply.started":"2025-10-21T14:47:04.952256Z","shell.execute_reply":"2025-10-21T15:14:18.092649Z"}},"outputs":[{"name":"stdout","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\ntokenizer_config.json: 7.30kB [00:00, 14.1MB/s]\nvocab.json: 2.78MB [00:00, 48.0MB/s]\nmerges.txt: 1.67MB [00:00, 115MB/s]\ntokenizer.json: 7.03MB [00:00, 154MB/s]\nconfig.json: 100%|█████████████████████████████| 663/663 [00:00<00:00, 3.07MB/s]\nmodel.safetensors.index.json: 27.8kB [00:00, 47.5MB/s]\nFetching 4 files:   0%|                                   | 0/4 [00:00<?, ?it/s]\nmodel-00001-of-00004.safetensors:   0%|             | 0.00/3.95G [00:00<?, ?B/s]\u001b[A\n\nmodel-00002-of-00004.safetensors:   0%|             | 0.00/3.86G [00:00<?, ?B/s]\u001b[A\u001b[A\nmodel-00003-of-00004.safetensors:   0%|             | 0.00/3.86G [00:00<?, ?B/s]\u001b[A\n\nmodel-00004-of-00004.safetensors:   0%|             | 0.00/3.56G [00:00<?, ?B/s]\u001b[A\u001b[A\n\nmodel-00004-of-00004.safetensors:   0%| | 8.13k/3.56G [00:00<83:13:11, 11.9kB/s]\u001b[A\u001b[A\n\nmodel-00004-of-00004.safetensors:   0%|    | 165k/3.56G [00:00<3:31:41, 280kB/s]\u001b[A\u001b[A\nmodel-00003-of-00004.safetensors:   0%|    | 1.37M/3.86G [00:00<38:18, 1.68MB/s]\u001b[A\n\nmodel-00004-of-00004.safetensors:   0%|     | 991k/3.56G [00:00<38:43, 1.53MB/s]\u001b[A\u001b[A\n\nmodel-00002-of-00004.safetensors:   1%|    | 29.3M/3.86G [00:01<02:51, 22.3MB/s]\u001b[A\u001b[A\nmodel-00003-of-00004.safetensors:   0%|    | 8.53M/3.86G [00:01<09:00, 7.13MB/s]\u001b[A\n\nmodel-00002-of-00004.safetensors:   1%|    | 33.7M/3.86G [00:01<02:44, 23.3MB/s]\u001b[A\u001b[A\nmodel-00003-of-00004.safetensors:   0%|    | 15.1M/3.86G [00:01<07:10, 8.95MB/s]\u001b[A\n\nmodel-00004-of-00004.safetensors:   0%|   | 1.42M/3.56G [00:01<1:17:08, 768kB/s]\u001b[A\u001b[A\n\nmodel-00002-of-00004.safetensors:   1%|    | 42.0M/3.86G [00:02<03:17, 19.4MB/s]\u001b[A\u001b[A\n\nmodel-00004-of-00004.safetensors:   0%|    | 7.25M/3.56G [00:02<10:05, 5.86MB/s]\u001b[A\u001b[A\nmodel-00003-of-00004.safetensors:   1%|    | 30.9M/3.86G [00:02<03:10, 20.1MB/s]\u001b[A\n\nmodel-00002-of-00004.safetensors:   1%|    | 45.5M/3.86G [00:02<03:44, 17.0MB/s]\u001b[A\u001b[A\nmodel-00001-of-00004.safetensors:   0%|    | 416k/3.95G [00:02<6:55:53, 158kB/s]\u001b[A\n\nmodel-00002-of-00004.safetensors:   1%|    | 49.5M/3.86G [00:02<04:27, 14.3MB/s]\u001b[A\u001b[A\n\nmodel-00004-of-00004.safetensors:   0%|    | 11.2M/3.56G [00:02<10:24, 5.68MB/s]\u001b[A\u001b[A\nmodel-00003-of-00004.safetensors:   1%|    | 34.3M/3.86G [00:02<04:40, 13.6MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:   0%|   | 1.73M/3.95G [00:03<1:37:17, 676kB/s]\u001b[A\n\nmodel-00002-of-00004.safetensors:   3%|▏    | 122M/3.86G [00:03<00:59, 62.6MB/s]\u001b[A\u001b[A\n\nmodel-00002-of-00004.safetensors:   3%|▏    | 129M/3.86G [00:03<01:03, 59.2MB/s]\u001b[A\u001b[A\n\nmodel-00002-of-00004.safetensors:   4%|▏    | 165M/3.86G [00:03<00:40, 91.7MB/s]\u001b[A\u001b[A\nmodel-00001-of-00004.safetensors:   0%|  | 2.84M/3.95G [00:03<1:05:07, 1.01MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:   1%|    | 47.9M/3.86G [00:03<04:38, 13.7MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:   0%|    | 5.75M/3.95G [00:03<24:50, 2.64MB/s]\u001b[A\n\nmodel-00002-of-00004.safetensors:   5%|▏    | 185M/3.86G [00:04<00:59, 62.1MB/s]\u001b[A\u001b[A\nmodel-00001-of-00004.safetensors:   0%|    | 6.99M/3.95G [00:04<22:47, 2.88MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:   3%|▏    | 115M/3.86G [00:04<01:19, 47.3MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:   4%|▏    | 147M/3.86G [00:04<00:57, 64.3MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:   0%|    | 8.20M/3.95G [00:04<25:33, 2.57MB/s]\u001b[A\n\nmodel-00002-of-00004.safetensors:   7%|▎    | 252M/3.86G [00:04<00:45, 78.7MB/s]\u001b[A\u001b[A\nmodel-00001-of-00004.safetensors:   0%|    | 8.75M/3.95G [00:04<25:08, 2.61MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:   4%|▏    | 173M/3.86G [00:05<01:08, 54.2MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:   7%|▍     | 272M/3.86G [00:05<00:29, 122MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:   8%|▍     | 301M/3.86G [00:05<00:30, 116MB/s]\u001b[A\n\nmodel-00002-of-00004.safetensors:   7%|▎    | 278M/3.86G [00:05<01:02, 57.8MB/s]\u001b[A\u001b[A\n\nmodel-00002-of-00004.safetensors:   8%|▍    | 294M/3.86G [00:05<01:01, 58.3MB/s]\u001b[A\u001b[A\n\nmodel-00002-of-00004.safetensors:   8%|▍    | 312M/3.86G [00:06<01:15, 46.8MB/s]\u001b[A\u001b[A\nmodel-00001-of-00004.safetensors:   0%|    | 9.27M/3.95G [00:06<58:26, 1.12MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:   9%|▍    | 367M/3.86G [00:06<00:44, 78.8MB/s]\u001b[A\n\nmodel-00004-of-00004.safetensors:   2%|    | 78.3M/3.56G [00:07<04:35, 12.6MB/s]\u001b[A\u001b[A\n\nmodel-00002-of-00004.safetensors:   9%|▍    | 335M/3.86G [00:07<01:37, 36.1MB/s]\u001b[A\u001b[A\n\nmodel-00002-of-00004.safetensors:  10%|▍    | 377M/3.86G [00:07<01:02, 56.1MB/s]\u001b[A\u001b[A\n\nmodel-00002-of-00004.safetensors:  11%|▌    | 406M/3.86G [00:08<00:57, 60.6MB/s]\u001b[A\u001b[A\n\nmodel-00002-of-00004.safetensors:  12%|▌    | 451M/3.86G [00:08<00:40, 84.7MB/s]\u001b[A\u001b[A\nmodel-00003-of-00004.safetensors:  11%|▌    | 442M/3.86G [00:08<00:58, 58.7MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:   0%|    | 13.2M/3.95G [00:08<42:47, 1.53MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:   0%|    | 14.0M/3.95G [00:09<45:30, 1.44MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  13%|▋    | 509M/3.86G [00:09<00:54, 61.9MB/s]\u001b[A\n\nmodel-00002-of-00004.safetensors:  12%|▌    | 481M/3.86G [00:09<01:05, 51.3MB/s]\u001b[A\u001b[A\nmodel-00001-of-00004.safetensors:   0%|    | 15.0M/3.95G [00:09<38:44, 1.69MB/s]\u001b[A\n\nmodel-00002-of-00004.safetensors:  13%|▋    | 503M/3.86G [00:09<00:57, 58.4MB/s]\u001b[A\u001b[A\n\nmodel-00004-of-00004.safetensors:   3%|▏    | 111M/3.56G [00:09<04:23, 13.1MB/s]\u001b[A\u001b[A\n\nmodel-00002-of-00004.safetensors:  14%|▋    | 532M/3.86G [00:11<01:23, 39.9MB/s]\u001b[A\u001b[A\nmodel-00001-of-00004.safetensors:   0%|    | 16.9M/3.95G [00:11<43:34, 1.50MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:   0%|    | 17.6M/3.95G [00:11<42:44, 1.53MB/s]\u001b[A\n\nmodel-00002-of-00004.safetensors:  14%|▋    | 556M/3.86G [00:11<01:23, 39.6MB/s]\u001b[A\u001b[A\n\nmodel-00002-of-00004.safetensors:  15%|▊    | 585M/3.86G [00:11<01:05, 50.2MB/s]\u001b[A\u001b[A\n\nmodel-00002-of-00004.safetensors:  17%|▊    | 642M/3.86G [00:12<00:56, 57.3MB/s]\u001b[A\u001b[A\n\nmodel-00004-of-00004.safetensors:   4%|▏    | 145M/3.56G [00:12<04:34, 12.4MB/s]\u001b[A\u001b[A\nmodel-00003-of-00004.safetensors:  14%|▋    | 540M/3.86G [00:12<01:50, 30.0MB/s]\u001b[A\n\nmodel-00004-of-00004.safetensors:   5%|▏    | 170M/3.56G [00:13<03:28, 16.2MB/s]\u001b[A\u001b[A\nmodel-00001-of-00004.safetensors:   0%|  | 18.3M/3.95G [00:13<1:05:19, 1.00MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  15%|▊    | 592M/3.86G [00:13<01:25, 38.4MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:   1%|    | 26.1M/3.95G [00:13<17:45, 3.68MB/s]\u001b[A\n\nmodel-00002-of-00004.safetensors:  18%|▉    | 698M/3.86G [00:13<00:53, 59.3MB/s]\u001b[A\u001b[A\n\nmodel-00002-of-00004.safetensors:  19%|▉    | 744M/3.86G [00:14<00:56, 55.6MB/s]\u001b[A\u001b[A\nmodel-00003-of-00004.safetensors:  16%|▊    | 623M/3.86G [00:14<01:35, 34.1MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  18%|▉    | 690M/3.86G [00:16<01:20, 39.5MB/s]\u001b[A\n\nmodel-00004-of-00004.safetensors:   5%|▎    | 193M/3.56G [00:16<04:27, 12.6MB/s]\u001b[A\u001b[A\n\nmodel-00004-of-00004.safetensors:   8%|▍    | 280M/3.56G [00:17<02:13, 24.5MB/s]\u001b[A\u001b[A\n\nmodel-00002-of-00004.safetensors:  20%|▉    | 773M/3.86G [00:17<01:53, 27.2MB/s]\u001b[A\u001b[A\nmodel-00003-of-00004.safetensors:  20%|▉    | 757M/3.86G [00:17<01:16, 40.9MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  20%|█    | 783M/3.86G [00:20<02:07, 24.1MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:   1%|   | 27.2M/3.95G [00:20<1:12:48, 897kB/s]\u001b[A\n\nmodel-00002-of-00004.safetensors:  23%|█▏   | 907M/3.86G [00:21<01:29, 33.1MB/s]\u001b[A\u001b[A\n\nmodel-00004-of-00004.safetensors:   9%|▍    | 319M/3.56G [00:21<03:04, 17.6MB/s]\u001b[A\u001b[A\n\nmodel-00002-of-00004.safetensors:  26%|█▎   | 999M/3.86G [00:21<00:58, 48.9MB/s]\u001b[A\u001b[A\nmodel-00003-of-00004.safetensors:  22%|█    | 850M/3.86G [00:21<01:30, 33.2MB/s]\u001b[A\n\nmodel-00002-of-00004.safetensors:  28%|█   | 1.07G/3.86G [00:22<00:50, 55.1MB/s]\u001b[A\u001b[A\nmodel-00001-of-00004.safetensors:   1%|   | 28.0M/3.95G [00:22<1:15:46, 862kB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  24%|█▏   | 917M/3.86G [00:22<01:07, 43.6MB/s]\u001b[A\n\nmodel-00004-of-00004.safetensors:  13%|▋    | 453M/3.56G [00:22<01:37, 31.9MB/s]\u001b[A\u001b[A\n\nmodel-00002-of-00004.safetensors:  31%|█▏  | 1.20G/3.86G [00:23<00:34, 76.5MB/s]\u001b[A\u001b[A\n\nmodel-00004-of-00004.safetensors:  15%|▋    | 520M/3.56G [00:23<01:11, 42.7MB/s]\u001b[A\u001b[A\n\nmodel-00002-of-00004.safetensors:  33%|█▎  | 1.27G/3.86G [00:23<00:29, 87.0MB/s]\u001b[A\u001b[A\nmodel-00003-of-00004.safetensors:  27%|█   | 1.05G/3.86G [00:23<00:45, 61.3MB/s]\u001b[A\n\nmodel-00004-of-00004.safetensors:  17%|▊    | 607M/3.56G [00:23<00:51, 57.5MB/s]\u001b[A\u001b[A\n\nmodel-00002-of-00004.safetensors:  35%|█▋   | 1.34G/3.86G [00:23<00:24, 105MB/s]\u001b[A\u001b[A\nmodel-00003-of-00004.safetensors:  29%|█▏  | 1.12G/3.86G [00:23<00:36, 75.3MB/s]\u001b[A\n\nmodel-00002-of-00004.safetensors:  35%|█▍  | 1.37G/3.86G [00:24<00:29, 84.8MB/s]\u001b[A\u001b[A\nmodel-00003-of-00004.safetensors:  31%|█▏  | 1.19G/3.86G [00:24<00:36, 73.2MB/s]\u001b[A\n\nmodel-00004-of-00004.safetensors:  18%|▉    | 632M/3.56G [00:24<01:01, 47.5MB/s]\u001b[A\u001b[A\nmodel-00003-of-00004.safetensors:  32%|█▎  | 1.25G/3.86G [00:25<00:31, 81.7MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  34%|█▎  | 1.33G/3.86G [00:26<00:30, 83.9MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:   1%|   | 29.9M/3.95G [00:26<1:35:24, 684kB/s]\u001b[A\n\nmodel-00004-of-00004.safetensors:  20%|▉    | 706M/3.56G [00:27<01:07, 42.3MB/s]\u001b[A\u001b[A\n\nmodel-00002-of-00004.safetensors:  37%|█▍  | 1.43G/3.86G [00:27<00:49, 49.4MB/s]\u001b[A\u001b[A\n\nmodel-00004-of-00004.safetensors:  22%|█    | 773M/3.56G [00:27<00:48, 57.7MB/s]\u001b[A\u001b[A\n\nmodel-00002-of-00004.safetensors:  38%|█▌  | 1.46G/3.86G [00:27<00:47, 51.0MB/s]\u001b[A\u001b[A\nmodel-00003-of-00004.safetensors:  36%|█▍  | 1.39G/3.86G [00:27<00:36, 66.9MB/s]\u001b[A\n\nmodel-00002-of-00004.safetensors:  39%|█▌  | 1.53G/3.86G [00:28<00:36, 63.6MB/s]\u001b[A\u001b[A\n\nmodel-00004-of-00004.safetensors:  24%|█▏   | 840M/3.56G [00:28<00:51, 53.0MB/s]\u001b[A\u001b[A\nmodel-00003-of-00004.safetensors:  38%|█▌  | 1.46G/3.86G [00:29<00:38, 63.0MB/s]\u001b[A\n\nmodel-00004-of-00004.safetensors:  27%|█▎   | 974M/3.56G [00:29<00:28, 90.5MB/s]\u001b[A\u001b[A\n\nmodel-00004-of-00004.safetensors:  28%|█   | 1.00G/3.56G [00:30<00:36, 70.2MB/s]\u001b[A\u001b[A\nmodel-00003-of-00004.safetensors:  40%|█▌  | 1.53G/3.86G [00:30<00:42, 54.7MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  40%|█▌  | 1.54G/3.86G [00:30<00:44, 52.5MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  42%|█▋  | 1.61G/3.86G [00:32<00:49, 45.2MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  43%|█▋  | 1.67G/3.86G [00:34<00:46, 46.9MB/s]\u001b[A\n\nmodel-00004-of-00004.safetensors:  30%|█▏  | 1.08G/3.56G [00:34<01:06, 37.2MB/s]\u001b[A\u001b[A\n\nmodel-00002-of-00004.safetensors:  41%|█▋  | 1.59G/3.86G [00:34<01:33, 24.4MB/s]\u001b[A\u001b[A\nmodel-00003-of-00004.safetensors:  45%|█▊  | 1.74G/3.86G [00:34<00:34, 61.8MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  47%|█▊  | 1.81G/3.86G [00:37<00:48, 42.2MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:   1%|   | 36.6M/3.95G [00:37<1:41:30, 642kB/s]\u001b[A\n\nmodel-00004-of-00004.safetensors:  32%|█▎  | 1.15G/3.56G [00:37<01:19, 30.4MB/s]\u001b[A\u001b[A\nmodel-00003-of-00004.safetensors:  49%|█▉  | 1.87G/3.86G [00:37<00:34, 57.3MB/s]\u001b[A\n\nmodel-00002-of-00004.safetensors:  43%|█▋  | 1.66G/3.86G [00:38<01:41, 21.7MB/s]\u001b[A\u001b[A\nmodel-00003-of-00004.safetensors:  51%|██  | 1.96G/3.86G [00:39<00:37, 51.2MB/s]\u001b[A\n\nmodel-00004-of-00004.safetensors:  34%|█▎  | 1.21G/3.56G [00:39<01:17, 30.3MB/s]\u001b[A\u001b[A\n\nmodel-00004-of-00004.safetensors:  35%|█▍  | 1.24G/3.56G [00:41<01:33, 24.9MB/s]\u001b[A\u001b[A\nmodel-00003-of-00004.safetensors:  54%|██▏ | 2.09G/3.86G [00:42<00:38, 46.4MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  57%|██▎ | 2.19G/3.86G [00:44<00:35, 48.0MB/s]\u001b[A\n\nmodel-00004-of-00004.safetensors:  36%|█▍  | 1.28G/3.56G [00:44<01:50, 20.5MB/s]\u001b[A\u001b[A\nmodel-00003-of-00004.safetensors:  57%|██▎ | 2.21G/3.86G [00:45<00:39, 41.7MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  58%|██▎ | 2.25G/3.86G [00:45<00:32, 49.4MB/s]\u001b[A\n\nmodel-00004-of-00004.safetensors:  37%|█▍  | 1.31G/3.56G [00:45<01:44, 21.5MB/s]\u001b[A\u001b[A\nmodel-00003-of-00004.safetensors:  59%|██▎ | 2.28G/3.86G [00:46<00:33, 46.7MB/s]\u001b[A\n\nmodel-00004-of-00004.safetensors:  38%|█▌  | 1.35G/3.56G [00:46<01:26, 25.4MB/s]\u001b[A\u001b[A\n\nmodel-00002-of-00004.safetensors:  45%|█▊  | 1.73G/3.86G [00:46<02:33, 13.9MB/s]\u001b[A\u001b[A\nmodel-00003-of-00004.safetensors:  59%|██▎ | 2.29G/3.86G [00:47<00:35, 44.8MB/s]\u001b[A\n\nmodel-00004-of-00004.safetensors:  40%|█▌  | 1.42G/3.56G [00:47<00:55, 38.9MB/s]\u001b[A\u001b[A\n\nmodel-00004-of-00004.safetensors:  42%|█▋  | 1.49G/3.56G [00:47<00:35, 58.7MB/s]\u001b[A\u001b[A\nmodel-00001-of-00004.safetensors:   1%|   | 36.6M/3.95G [00:49<1:41:30, 642kB/s]\u001b[A\n\nmodel-00002-of-00004.safetensors:  45%|█▊  | 1.76G/3.86G [00:52<03:13, 10.9MB/s]\u001b[A\u001b[A\n\nmodel-00004-of-00004.safetensors:  43%|█▋  | 1.53G/3.56G [00:52<01:28, 22.9MB/s]\u001b[A\u001b[A\n\nmodel-00002-of-00004.safetensors:  47%|█▉  | 1.82G/3.86G [00:52<02:11, 15.6MB/s]\u001b[A\u001b[A\nmodel-00003-of-00004.safetensors:  61%|██▍ | 2.36G/3.86G [00:53<01:18, 19.2MB/s]\u001b[A\n\nmodel-00002-of-00004.safetensors:  51%|██  | 1.95G/3.86G [00:54<01:15, 25.3MB/s]\u001b[A\u001b[A\n\nmodel-00002-of-00004.safetensors:  52%|██  | 2.02G/3.86G [00:56<01:04, 28.5MB/s]\u001b[A\u001b[A\n\nmodel-00002-of-00004.safetensors:  54%|██▏ | 2.08G/3.86G [00:56<00:51, 34.8MB/s]\u001b[A\u001b[A\nmodel-00001-of-00004.safetensors:   1%|   | 36.7M/3.95G [00:56<4:19:51, 251kB/s]\u001b[A\n\nmodel-00002-of-00004.safetensors:  55%|██▏ | 2.12G/3.86G [00:57<00:42, 41.3MB/s]\u001b[A\u001b[A\n\nmodel-00002-of-00004.safetensors:  57%|██▎ | 2.19G/3.86G [00:58<00:32, 50.8MB/s]\u001b[A\u001b[A\n\nmodel-00002-of-00004.safetensors:  60%|██▍ | 2.32G/3.86G [00:59<00:21, 70.6MB/s]\u001b[A\u001b[A\n\nmodel-00002-of-00004.safetensors:  62%|██▍ | 2.39G/3.86G [01:00<00:25, 57.2MB/s]\u001b[A\u001b[A\n\nmodel-00002-of-00004.safetensors:  63%|██▌ | 2.42G/3.86G [01:01<00:28, 49.9MB/s]\u001b[A\u001b[A\n\nmodel-00002-of-00004.safetensors:  64%|██▌ | 2.49G/3.86G [01:04<00:32, 42.1MB/s]\u001b[A\u001b[A\nmodel-00003-of-00004.safetensors:  65%|██▌ | 2.49G/3.86G [01:05<01:38, 14.0MB/s]\u001b[A\n\nmodel-00002-of-00004.safetensors:  66%|██▋ | 2.55G/3.86G [01:05<00:28, 46.5MB/s]\u001b[A\u001b[A\n\nmodel-00004-of-00004.safetensors:  45%|█▊  | 1.60G/3.56G [01:05<03:09, 10.3MB/s]\u001b[A\u001b[A\n\nmodel-00002-of-00004.safetensors:  68%|██▋ | 2.62G/3.86G [01:05<00:21, 57.2MB/s]\u001b[A\u001b[A\n\nmodel-00004-of-00004.safetensors:  47%|█▊  | 1.66G/3.56G [01:05<02:02, 15.4MB/s]\u001b[A\u001b[A\nmodel-00003-of-00004.safetensors:  65%|██▌ | 2.52G/3.86G [01:05<01:30, 14.9MB/s]\u001b[A\n\nmodel-00004-of-00004.safetensors:  49%|█▉  | 1.76G/3.56G [01:06<01:11, 25.3MB/s]\u001b[A\u001b[A\n\nmodel-00002-of-00004.safetensors:  70%|██▊ | 2.69G/3.86G [01:06<00:17, 68.0MB/s]\u001b[A\u001b[A\n\nmodel-00004-of-00004.safetensors:  51%|██  | 1.80G/3.56G [01:06<00:58, 30.2MB/s]\u001b[A\u001b[A\n\nmodel-00004-of-00004.safetensors:  53%|██  | 1.88G/3.56G [01:06<00:37, 44.1MB/s]\u001b[A\u001b[A\n\nmodel-00002-of-00004.safetensors:  73%|███▋ | 2.82G/3.86G [01:06<00:10, 103MB/s]\u001b[A\u001b[A\nmodel-00003-of-00004.safetensors:  66%|██▋ | 2.54G/3.86G [01:06<01:24, 15.7MB/s]\u001b[A\n\nmodel-00002-of-00004.safetensors:  74%|███▋ | 2.87G/3.86G [01:07<00:09, 108MB/s]\u001b[A\u001b[A\n\nmodel-00002-of-00004.safetensors:  78%|███▉ | 3.00G/3.86G [01:07<00:05, 168MB/s]\u001b[A\u001b[A\n\nmodel-00004-of-00004.safetensors:  55%|██▏ | 1.95G/3.56G [01:07<00:30, 52.0MB/s]\u001b[A\u001b[A\n\nmodel-00004-of-00004.safetensors:  59%|██▎ | 2.09G/3.56G [01:07<00:17, 85.4MB/s]\u001b[A\u001b[A\nmodel-00001-of-00004.safetensors:   3%|▏    | 104M/3.95G [01:07<29:34, 2.17MB/s]\u001b[A\n\nmodel-00002-of-00004.safetensors:  79%|███▉ | 3.07G/3.86G [01:08<00:05, 148MB/s]\u001b[A\u001b[A\n\nmodel-00004-of-00004.safetensors:  61%|██▍ | 2.15G/3.56G [01:08<00:15, 92.7MB/s]\u001b[A\u001b[A\nmodel-00003-of-00004.safetensors:  67%|██▋ | 2.61G/3.86G [01:08<01:01, 20.6MB/s]\u001b[A\n\nmodel-00002-of-00004.safetensors:  81%|████ | 3.14G/3.86G [01:08<00:05, 140MB/s]\u001b[A\u001b[A\nmodel-00003-of-00004.safetensors:  68%|██▋ | 2.63G/3.86G [01:08<00:51, 24.0MB/s]\u001b[A\n\nmodel-00002-of-00004.safetensors:  83%|████▏| 3.21G/3.86G [01:09<00:04, 135MB/s]\u001b[A\u001b[A\nmodel-00003-of-00004.safetensors:  70%|██▊ | 2.70G/3.86G [01:09<00:33, 35.0MB/s]\u001b[A\n\nmodel-00002-of-00004.safetensors:  84%|████▏| 3.26G/3.86G [01:09<00:04, 132MB/s]\u001b[A\u001b[A\n\nmodel-00004-of-00004.safetensors:  62%|██▍ | 2.22G/3.56G [01:09<00:17, 75.8MB/s]\u001b[A\u001b[A\n\nmodel-00002-of-00004.safetensors:  86%|████▎| 3.33G/3.86G [01:10<00:04, 122MB/s]\u001b[A\u001b[A\n\nmodel-00004-of-00004.safetensors:  64%|██▌ | 2.29G/3.56G [01:10<00:15, 81.1MB/s]\u001b[A\u001b[A\n\nmodel-00002-of-00004.safetensors:  88%|████▍| 3.40G/3.86G [01:11<00:04, 108MB/s]\u001b[A\u001b[A\n\nmodel-00004-of-00004.safetensors:  66%|██▋ | 2.35G/3.56G [01:11<00:14, 80.5MB/s]\u001b[A\u001b[A\n\nmodel-00002-of-00004.safetensors:  90%|███▌| 3.47G/3.86G [01:12<00:04, 85.1MB/s]\u001b[A\u001b[A\n\nmodel-00004-of-00004.safetensors:  68%|██▋ | 2.42G/3.56G [01:12<00:16, 68.5MB/s]\u001b[A\u001b[A\n\nmodel-00002-of-00004.safetensors:  91%|███▋| 3.53G/3.86G [01:13<00:04, 68.1MB/s]\u001b[A\u001b[A\nmodel-00003-of-00004.safetensors:  71%|██▊ | 2.75G/3.86G [01:13<00:51, 21.6MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  73%|██▉ | 2.82G/3.86G [01:14<00:36, 29.1MB/s]\u001b[A\n\nmodel-00002-of-00004.safetensors:  93%|███▋| 3.60G/3.86G [01:14<00:03, 69.5MB/s]\u001b[A\u001b[A\nmodel-00003-of-00004.safetensors:  75%|██▉ | 2.88G/3.86G [01:15<00:24, 39.8MB/s]\u001b[A\n\nmodel-00002-of-00004.safetensors:  95%|███▊| 3.66G/3.86G [01:15<00:02, 82.6MB/s]\u001b[A\u001b[A\nmodel-00003-of-00004.safetensors:  76%|███ | 2.93G/3.86G [01:15<00:18, 49.4MB/s]\u001b[A\n\nmodel-00002-of-00004.safetensors:  97%|███▊| 3.73G/3.86G [01:15<00:01, 97.1MB/s]\u001b[A\u001b[A\nmodel-00003-of-00004.safetensors:  78%|███ | 3.00G/3.86G [01:15<00:13, 65.9MB/s]\u001b[A\n\nmodel-00002-of-00004.safetensors:  98%|████▉| 3.80G/3.86G [01:15<00:00, 109MB/s]\u001b[A\u001b[A\n\nmodel-00004-of-00004.safetensors:  70%|██▊ | 2.49G/3.56G [01:16<00:27, 38.3MB/s]\u001b[A\u001b[A\n\nmodel-00002-of-00004.safetensors: 100%|████| 3.86G/3.86G [01:16<00:00, 50.6MB/s]\u001b[A\u001b[A\n\nmodel-00001-of-00004.safetensors:   4%|▏    | 171M/3.95G [01:16<17:06, 3.68MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:   5%|▏    | 183M/3.95G [01:16<14:49, 4.23MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  79%|███▏| 3.07G/3.86G [01:16<00:12, 65.7MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:   5%|▏    | 190M/3.95G [01:16<13:39, 4.58MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:   5%|▏    | 196M/3.95G [01:16<12:13, 5.11MB/s]\u001b[A\n\nmodel-00004-of-00004.safetensors:  71%|██▊ | 2.53G/3.56G [01:17<00:25, 40.4MB/s]\u001b[A\u001b[A\nmodel-00001-of-00004.safetensors:   5%|▎    | 202M/3.95G [01:17<10:47, 5.78MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:   5%|▎    | 213M/3.95G [01:17<08:06, 7.67MB/s]\u001b[A\n\nmodel-00004-of-00004.safetensors:  73%|██▉ | 2.59G/3.56G [01:17<00:17, 55.7MB/s]\u001b[A\u001b[A\nmodel-00001-of-00004.safetensors:   6%|▎    | 222M/3.95G [01:17<06:30, 9.53MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:   6%|▎    | 231M/3.95G [01:17<05:04, 12.2MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:   6%|▎    | 243M/3.95G [01:17<03:36, 17.1MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:   7%|▎    | 276M/3.95G [01:17<01:45, 34.9MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  81%|███▏| 3.13G/3.86G [01:17<00:11, 66.0MB/s]\u001b[A\n\nmodel-00004-of-00004.safetensors:  75%|██▉ | 2.66G/3.56G [01:17<00:13, 64.3MB/s]\u001b[A\u001b[A\nmodel-00001-of-00004.safetensors:   8%|▍    | 311M/3.95G [01:18<01:19, 45.8MB/s]\u001b[A\n\nmodel-00004-of-00004.safetensors:  76%|███ | 2.69G/3.56G [01:18<00:13, 64.7MB/s]\u001b[A\u001b[A\nmodel-00003-of-00004.safetensors:  83%|███▎| 3.20G/3.86G [01:19<00:10, 61.0MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:   8%|▍    | 324M/3.95G [01:19<02:16, 26.6MB/s]\u001b[A\n\nmodel-00004-of-00004.safetensors:  77%|███ | 2.75G/3.56G [01:20<00:16, 50.1MB/s]\u001b[A\u001b[A\nmodel-00001-of-00004.safetensors:   8%|▍    | 332M/3.95G [01:20<03:20, 18.0MB/s]\u001b[A\n\nmodel-00004-of-00004.safetensors:  79%|███▏| 2.82G/3.56G [01:21<00:13, 54.3MB/s]\u001b[A\u001b[A\nmodel-00003-of-00004.safetensors:  85%|███▍| 3.27G/3.86G [01:22<00:14, 39.9MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  86%|███▍| 3.34G/3.86G [01:22<00:09, 54.6MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:   9%|▍    | 349M/3.95G [01:22<04:12, 14.2MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  88%|███▌| 3.40G/3.86G [01:22<00:06, 66.1MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:   9%|▍    | 375M/3.95G [01:23<03:07, 19.0MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  90%|███▌| 3.47G/3.86G [01:23<00:04, 78.9MB/s]\u001b[A\n\nmodel-00004-of-00004.safetensors:  80%|███▏| 2.86G/3.56G [01:23<00:19, 36.7MB/s]\u001b[A\u001b[A\nmodel-00001-of-00004.safetensors:  11%|▌    | 430M/3.95G [01:23<01:35, 36.7MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  12%|▌    | 469M/3.95G [01:23<01:08, 50.6MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  91%|███▋| 3.53G/3.86G [01:24<00:04, 69.6MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  14%|▋    | 536M/3.95G [01:24<00:53, 63.5MB/s]\u001b[A\n\nmodel-00004-of-00004.safetensors:  82%|███▎| 2.92G/3.56G [01:24<00:15, 40.2MB/s]\u001b[A\u001b[A\nmodel-00003-of-00004.safetensors:  93%|███▋| 3.59G/3.86G [01:25<00:04, 66.3MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  15%|▊    | 603M/3.95G [01:25<00:54, 61.9MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  95%|███▊| 3.66G/3.86G [01:26<00:02, 75.4MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  18%|▉    | 721M/3.95G [01:26<00:32, 98.7MB/s]\u001b[A\n\nmodel-00004-of-00004.safetensors:  83%|███▎| 2.96G/3.56G [01:26<00:17, 35.0MB/s]\u001b[A\u001b[A\nmodel-00001-of-00004.safetensors:  20%|▉    | 788M/3.95G [01:26<00:32, 96.2MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  21%|█    | 825M/3.95G [01:27<00:34, 89.8MB/s]\u001b[A\n\nmodel-00004-of-00004.safetensors:  84%|███▎| 2.99G/3.56G [01:28<00:21, 26.8MB/s]\u001b[A\u001b[A\nmodel-00001-of-00004.safetensors:  23%|█▏   | 892M/3.95G [01:29<00:46, 66.2MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  24%|█▏   | 959M/3.95G [01:30<00:56, 52.9MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  26%|█   | 1.01G/3.95G [01:32<01:01, 48.1MB/s]\u001b[A\n\nmodel-00004-of-00004.safetensors:  86%|███▍| 3.06G/3.56G [01:32<00:21, 22.8MB/s]\u001b[A\u001b[A\nmodel-00001-of-00004.safetensors:  27%|█   | 1.07G/3.95G [01:33<00:59, 48.4MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  27%|█   | 1.08G/3.95G [01:33<01:03, 45.2MB/s]\u001b[A\n\nmodel-00004-of-00004.safetensors:  87%|███▍| 3.09G/3.56G [01:33<00:20, 22.4MB/s]\u001b[A\u001b[A\nmodel-00001-of-00004.safetensors:  29%|█▏  | 1.13G/3.95G [01:34<00:47, 58.7MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  29%|█▏  | 1.16G/3.95G [01:34<00:42, 65.2MB/s]\u001b[A\n\nmodel-00004-of-00004.safetensors:  88%|███▌| 3.12G/3.56G [01:34<00:17, 24.8MB/s]\u001b[A\u001b[A\n\nmodel-00004-of-00004.safetensors:  91%|███▌| 3.22G/3.56G [01:34<00:07, 47.6MB/s]\u001b[A\u001b[A\nmodel-00001-of-00004.safetensors:  33%|█▋   | 1.29G/3.95G [01:34<00:22, 117MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  37%|█▊   | 1.45G/3.95G [01:35<00:12, 206MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  97%|███▊| 3.73G/3.86G [01:35<00:06, 19.7MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  39%|█▉   | 1.52G/3.95G [01:35<00:11, 208MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  98%|███▉| 3.80G/3.86G [01:35<00:02, 26.4MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  40%|██   | 1.59G/3.95G [01:35<00:13, 181MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  42%|██   | 1.65G/3.95G [01:36<00:11, 199MB/s]\u001b[A\n\nmodel-00004-of-00004.safetensors:  92%|███▋| 3.29G/3.56G [01:36<00:05, 46.0MB/s]\u001b[A\u001b[A\nmodel-00001-of-00004.safetensors:  43%|██▏  | 1.71G/3.95G [01:36<00:13, 170MB/s]\u001b[A\n\nmodel-00004-of-00004.safetensors:  94%|███▊| 3.36G/3.56G [01:36<00:03, 57.4MB/s]\u001b[A\u001b[A\n\nmodel-00004-of-00004.safetensors:  96%|███▊| 3.42G/3.56G [01:37<00:01, 68.0MB/s]\u001b[A\u001b[A\nmodel-00001-of-00004.safetensors:  45%|██▏  | 1.77G/3.95G [01:37<00:20, 107MB/s]\u001b[A\nmodel-00003-of-00004.safetensors: 100%|████| 3.86G/3.86G [01:38<00:00, 39.4MB/s]\u001b[A\n\n\nmodel-00004-of-00004.safetensors:  98%|███▉| 3.49G/3.56G [01:38<00:00, 72.8MB/s]\u001b[A\u001b[A\nmodel-00001-of-00004.safetensors:  47%|██▎  | 1.84G/3.95G [01:38<00:20, 102MB/s]\u001b[A\n\nmodel-00004-of-00004.safetensors: 100%|████| 3.56G/3.56G [01:39<00:00, 35.8MB/s]\u001b[A\u001b[A\n\nmodel-00001-of-00004.safetensors:  48%|█▉  | 1.88G/3.95G [01:39<00:26, 77.4MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  49%|█▉  | 1.95G/3.95G [01:41<00:34, 58.3MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  50%|██  | 1.98G/3.95G [01:42<00:36, 54.0MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  51%|██  | 2.01G/3.95G [01:42<00:37, 52.0MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  51%|██  | 2.01G/3.95G [01:42<00:37, 51.4MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  53%|██  | 2.08G/3.95G [01:44<00:42, 44.2MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  54%|██▏ | 2.15G/3.95G [01:45<00:30, 58.1MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  55%|██▏ | 2.17G/3.95G [01:45<00:27, 63.7MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  56%|██▏ | 2.20G/3.95G [01:45<00:23, 75.2MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  57%|██▎ | 2.25G/3.95G [01:45<00:18, 89.8MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  58%|██▉  | 2.29G/3.95G [01:46<00:14, 113MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  60%|██▉  | 2.35G/3.95G [01:46<00:12, 128MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  60%|██▍ | 2.38G/3.95G [01:47<00:16, 92.9MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  64%|███▏ | 2.51G/3.95G [01:47<00:09, 156MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  65%|███▎ | 2.58G/3.95G [01:47<00:08, 164MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  67%|███▎ | 2.65G/3.95G [01:48<00:07, 169MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  68%|███▍ | 2.67G/3.95G [01:48<00:07, 171MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  69%|██▊ | 2.72G/3.95G [01:53<00:42, 29.1MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  71%|██▊ | 2.79G/3.95G [01:53<00:26, 44.0MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  74%|██▉ | 2.92G/3.95G [01:53<00:11, 86.0MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  77%|███▊ | 3.05G/3.95G [01:54<00:06, 134MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  81%|████ | 3.19G/3.95G [01:54<00:03, 197MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  84%|████▏| 3.33G/3.95G [01:54<00:02, 269MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  86%|████▎| 3.41G/3.95G [01:54<00:01, 289MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  89%|████▍| 3.50G/3.95G [01:55<00:01, 222MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  90%|████▍| 3.55G/3.95G [01:55<00:01, 236MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  93%|████▋| 3.68G/3.95G [01:55<00:00, 291MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  96%|████▊| 3.80G/3.95G [01:55<00:00, 370MB/s]\u001b[A\nmodel-00001-of-00004.safetensors: 100%|████| 3.95G/3.95G [01:56<00:00, 34.0MB/s]\u001b[A\nFetching 4 files: 100%|███████████████████████████| 4/4 [01:56<00:00, 29.09s/it]\nFetching 4 files: 100%|███████████████████████████| 4/4 [01:56<00:00, 29.08s/it]\nLoading checkpoint shards: 100%|██████████████████| 4/4 [01:19<00:00, 19.97s/it]\ngeneration_config.json: 100%|██████████████████| 243/243 [00:00<00:00, 1.22MB/s]\nLoading checkpoint shards: 100%|██████████████████| 4/4 [01:20<00:00, 20.13s/it]\nunified_chip2.jsonl: 100%|█████████████████| 95.6M/95.6M [00:01<00:00, 76.6MB/s]\nGenerating train split: 210289 examples [00:00, 338014.09 examples/s]\nAdding EOS to train dataset: 100%|█| 21029/21029 [00:00<00:00, 23846.01 examples\nTokenizing train dataset: 100%|██| 21029/21029 [00:09<00:00, 2272.83 examples/s]\nTruncating train dataset: 100%|█| 21029/21029 [00:00<00:00, 516109.13 examples/s\n[Rank 0] Plugin FSDP version: 2\n[Rank 0] is_fsdp2: True\n[Rank 0] Distributed type: DistributedType.FSDP\n[Rank 0] Device: cuda:0\n[Rank 0] Pre-training Mem Alloc = 5.72GB, Mem Reserved = 7.21GB\ntrainable params: 40,370,176 || all params: 7,655,986,688 || trainable%: 0.5273\nThe tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151645}.\n[Rank 1] Plugin FSDP version: 2\n[Rank 1] is_fsdp2: True\n[Rank 1] Distributed type: DistributedType.FSDP\n[Rank 1] Device: cuda:1\n[Rank 1] Pre-training Mem Alloc = 5.72GB, Mem Reserved = 7.21GB\ntrainable params: 40,370,176 || all params: 7,655,986,688 || trainable%: 0.5273\nThe tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151645}.\n/usr/local/lib/python3.11/dist-packages/accelerate/utils/fsdp_utils.py:707: UserWarning: FSDP upcast of low precision parameters to fp32 (since mixed_precision != 'no') may affect the precision of model checkpoints.\n  warnings.warn(\n  5%|██▏                                        | 5/100 [01:11<22:16, 14.06s/it][Mem Alloc = 5.82GB, Mem Reserved = 15.17GB, Mem Peak = 12.34GB]\n{'loss': 3.8657, 'grad_norm': 2.526296854019165, 'learning_rate': 1e-05, 'entropy': 2.040966796875, 'num_tokens': 8134.0, 'mean_token_accuracy': 0.45526982974261043, 'epoch': 0.0}\n 10%|████▏                                     | 10/100 [02:18<20:07, 13.42s/it][Mem Alloc = 5.82GB, Mem Reserved = 15.17GB, Mem Peak = 12.34GB]\n{'loss': 3.2283, 'grad_norm': nan, 'learning_rate': 4.9473684210526315e-05, 'entropy': 2.04326171875, 'num_tokens': 15261.0, 'mean_token_accuracy': 0.46508185416460035, 'epoch': 0.01}\n 15%|██████▎                                   | 15/100 [03:27<19:34, 13.81s/it][Mem Alloc = 5.82GB, Mem Reserved = 15.17GB, Mem Peak = 12.34GB]\n{'loss': 3.3398, 'grad_norm': 2.2623629570007324, 'learning_rate': 4.736842105263158e-05, 'entropy': 2.2458740234375, 'num_tokens': 23928.0, 'mean_token_accuracy': 0.5022835299372673, 'epoch': 0.01}\n 20%|████████▍                                 | 20/100 [04:34<17:59, 13.49s/it][Mem Alloc = 5.82GB, Mem Reserved = 15.17GB, Mem Peak = 12.34GB]\n{'loss': 2.6954, 'grad_norm': 1.714545488357544, 'learning_rate': 4.473684210526316e-05, 'entropy': 2.06064453125, 'num_tokens': 30863.0, 'mean_token_accuracy': 0.5375141769647598, 'epoch': 0.02}\n 25%|██████████▌                               | 25/100 [05:42<16:53, 13.51s/it][Mem Alloc = 5.82GB, Mem Reserved = 15.17GB, Mem Peak = 12.34GB]\n{'loss': 2.3358, 'grad_norm': 1.8808114528656006, 'learning_rate': 4.210526315789474e-05, 'entropy': 2.0245849609375, 'num_tokens': 38127.0, 'mean_token_accuracy': 0.5424812287092209, 'epoch': 0.02}\n 30%|████████████▌                             | 30/100 [06:49<15:43, 13.48s/it][Mem Alloc = 5.82GB, Mem Reserved = 15.17GB, Mem Peak = 12.34GB]\n{'loss': 2.0531, 'grad_norm': 2.1472055912017822, 'learning_rate': 3.9473684210526316e-05, 'entropy': 1.9914794921875, 'num_tokens': 45550.0, 'mean_token_accuracy': 0.5505722776055336, 'epoch': 0.02}\n 35%|██████████████▋                           | 35/100 [07:56<14:28, 13.35s/it][Mem Alloc = 5.82GB, Mem Reserved = 15.17GB, Mem Peak = 12.34GB]\n{'loss': 1.7711, 'grad_norm': 0.9821584820747375, 'learning_rate': 3.6842105263157895e-05, 'entropy': 1.7681884765625, 'num_tokens': 52593.0, 'mean_token_accuracy': 0.5709909312427044, 'epoch': 0.03}\n 40%|████████████████▊                         | 40/100 [09:04<13:24, 13.41s/it][Mem Alloc = 5.82GB, Mem Reserved = 15.17GB, Mem Peak = 12.34GB]\n{'loss': 1.6978, 'grad_norm': 0.9288327693939209, 'learning_rate': 3.421052631578947e-05, 'entropy': 1.69169921875, 'num_tokens': 60009.0, 'mean_token_accuracy': 0.5930776722729206, 'epoch': 0.03}\n 45%|██████████████████▉                       | 45/100 [10:11<12:23, 13.52s/it][Mem Alloc = 5.82GB, Mem Reserved = 15.17GB, Mem Peak = 12.34GB]\n{'loss': 1.7082, 'grad_norm': 1.1069540977478027, 'learning_rate': 3.157894736842105e-05, 'entropy': 1.7107421875, 'num_tokens': 66736.0, 'mean_token_accuracy': 0.5949740834534168, 'epoch': 0.03}\n 50%|█████████████████████                     | 50/100 [11:18<11:12, 13.46s/it][Mem Alloc = 5.82GB, Mem Reserved = 15.17GB, Mem Peak = 12.34GB]\n{'loss': 1.6546, 'grad_norm': 0.5835407376289368, 'learning_rate': 2.8947368421052634e-05, 'entropy': 1.724658203125, 'num_tokens': 73817.0, 'mean_token_accuracy': 0.6000977970659733, 'epoch': 0.04}\n 55%|███████████████████████                   | 55/100 [12:26<10:12, 13.60s/it][Mem Alloc = 5.82GB, Mem Reserved = 15.17GB, Mem Peak = 12.34GB]\n{'loss': 1.5659, 'grad_norm': 0.7680076360702515, 'learning_rate': 2.6315789473684212e-05, 'entropy': 1.5009521484375, 'num_tokens': 81350.0, 'mean_token_accuracy': 0.6092428117990494, 'epoch': 0.04}\n 60%|█████████████████████████▏                | 60/100 [13:34<09:01, 13.54s/it][Mem Alloc = 5.82GB, Mem Reserved = 15.17GB, Mem Peak = 12.34GB]\n{'loss': 1.614, 'grad_norm': 0.6504882574081421, 'learning_rate': 2.368421052631579e-05, 'entropy': 1.5529541015625, 'num_tokens': 88488.0, 'mean_token_accuracy': 0.5923964850604534, 'epoch': 0.05}\n 65%|███████████████████████████▎              | 65/100 [14:41<07:52, 13.49s/it][Mem Alloc = 5.82GB, Mem Reserved = 15.17GB, Mem Peak = 12.34GB]\n{'loss': 1.6387, 'grad_norm': 0.5719472765922546, 'learning_rate': 2.105263157894737e-05, 'entropy': 1.6416015625, 'num_tokens': 95358.0, 'mean_token_accuracy': 0.595086582750082, 'epoch': 0.05}\n 70%|█████████████████████████████▍            | 70/100 [15:49<06:46, 13.55s/it][Mem Alloc = 5.82GB, Mem Reserved = 15.17GB, Mem Peak = 12.34GB]\n{'loss': 1.5836, 'grad_norm': 0.5689281225204468, 'learning_rate': 1.8421052631578947e-05, 'entropy': 1.5698486328125, 'num_tokens': 102339.0, 'mean_token_accuracy': 0.6083387635648251, 'epoch': 0.05}\n 75%|███████████████████████████████▌          | 75/100 [16:56<05:35, 13.43s/it][Mem Alloc = 5.82GB, Mem Reserved = 15.17GB, Mem Peak = 12.34GB]\n{'loss': 1.6268, 'grad_norm': 0.6166877746582031, 'learning_rate': 1.5789473684210526e-05, 'entropy': 1.6183837890625, 'num_tokens': 109363.0, 'mean_token_accuracy': 0.6112268052995204, 'epoch': 0.06}\n 80%|█████████████████████████████████▌        | 80/100 [18:03<04:28, 13.42s/it][Mem Alloc = 5.82GB, Mem Reserved = 15.17GB, Mem Peak = 12.34GB]\n{'loss': 1.4514, 'grad_norm': 0.6900585889816284, 'learning_rate': 1.3157894736842106e-05, 'entropy': 1.5143310546875, 'num_tokens': 115948.0, 'mean_token_accuracy': 0.6296519435942173, 'epoch': 0.06}\n 85%|███████████████████████████████████▋      | 85/100 [19:09<03:19, 13.30s/it][Mem Alloc = 5.82GB, Mem Reserved = 15.17GB, Mem Peak = 12.34GB]\n{'loss': 1.4711, 'grad_norm': 0.588306188583374, 'learning_rate': 1.0526315789473684e-05, 'entropy': 1.51827392578125, 'num_tokens': 122755.0, 'mean_token_accuracy': 0.6258546084165573, 'epoch': 0.06}\n 90%|█████████████████████████████████████▊    | 90/100 [20:16<02:12, 13.29s/it][Mem Alloc = 5.82GB, Mem Reserved = 15.17GB, Mem Peak = 12.34GB]\n{'loss': 1.491, 'grad_norm': 0.5657914876937866, 'learning_rate': 7.894736842105263e-06, 'entropy': 1.511181640625, 'num_tokens': 129596.0, 'mean_token_accuracy': 0.6274742528796196, 'epoch': 0.07}\n 95%|███████████████████████████████████████▉  | 95/100 [21:24<01:07, 13.55s/it][Mem Alloc = 5.82GB, Mem Reserved = 15.17GB, Mem Peak = 12.34GB]\n{'loss': 1.3343, 'grad_norm': 0.6713659763336182, 'learning_rate': 5.263157894736842e-06, 'entropy': 1.337060546875, 'num_tokens': 136717.0, 'mean_token_accuracy': 0.640120629966259, 'epoch': 0.07}\n100%|█████████████████████████████████████████| 100/100 [22:31<00:00, 13.36s/it][Mem Alloc = 5.82GB, Mem Reserved = 15.17GB, Mem Peak = 12.34GB]\n{'loss': 1.5409, 'grad_norm': 0.6667943000793457, 'learning_rate': 2.631578947368421e-06, 'entropy': 1.517236328125, 'num_tokens': 143484.0, 'mean_token_accuracy': 0.6130416162312031, 'epoch': 0.08}\n100%|█████████████████████████████████████████| 100/100 [22:31<00:00, 13.36s/it][Mem Alloc = 5.82GB, Mem Reserved = 13.61GB, Mem Peak = 12.34GB]\n{'train_runtime': 1366.825, 'train_samples_per_second': 1.171, 'train_steps_per_second': 0.073, 'train_loss': 1.9833706665039061, 'epoch': 0.08}\n100%|█████████████████████████████████████████| 100/100 [22:46<00:00, 13.67s/it]\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Training Loss Visualization\n\nSince no evaluation dataset is used, we plot the training loss from the saved logs. The GPUUsageCallback saves logs to train_logs.json, which we load and visualize.","metadata":{}},{"cell_type":"code","source":"import json\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Load training logs\nlog_file = \"/kaggle/working/output/train_logs.json\"\ntrain_entries = []\nwith open(log_file, \"r\") as f:\n    for line in f:\n        log = json.loads(line)\n        if log.get(\"loss\") is not None:\n            train_entries.append((log[\"step\"], log[\"loss\"]))\n\n# Extract steps and losses\ntrain_steps, train_losses = zip(*train_entries) if train_entries else ([], [])\n\n# Plot\nplt.style.use('seaborn-v0_8')\nsns.set_palette(\"pastel\")\nplt.figure(figsize=(8, 4))\nplt.plot(train_steps, train_losses, marker='o', label='Training Loss')\nplt.xlabel(\"Step\")\nplt.ylabel(\"Loss\")\nplt.title(\"Training Loss over Steps\")\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T15:14:43.987266Z","iopub.execute_input":"2025-10-21T15:14:43.987591Z","iopub.status.idle":"2025-10-21T15:14:44.518057Z","shell.execute_reply.started":"2025-10-21T15:14:43.987569Z","shell.execute_reply":"2025-10-21T15:14:44.517382Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 800x400 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}